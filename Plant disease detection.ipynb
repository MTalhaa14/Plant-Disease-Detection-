{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Define the path to the dataset\n",
        "dataset_directory = \"/content/drive/MyDrive/Tomatoes\"\n",
        "\n",
        "# Define transformations for the dataset (resize and normalize)\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load the dataset\n",
        "image_dataset = datasets.ImageFolder(dataset_directory, transform=data_transform)\n",
        "\n",
        "# Access and print the class names\n",
        "class_names = image_dataset.classes\n",
        "print(\"Class Names:\", class_names)\n",
        "\n",
        "# Function to display images\n",
        "def display_images(class_name, images, n=5):\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    for i in range(n):\n",
        "        plt.subplot(1, n, i + 1)\n",
        "        plt.imshow(images[i].permute(1, 2, 0))  # Convert from tensor to numpy array for display\n",
        "        plt.title(class_name)\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Load and display images from each class\n",
        "for class_name in class_names:\n",
        "    class_dir = os.path.join(dataset_directory, class_name)\n",
        "    images = []\n",
        "    image_files = sorted(os.listdir(class_dir))[:5]  # Get the first 5 images\n",
        "    for image_file in image_files:\n",
        "        img_path = os.path.join(class_dir, image_file)\n",
        "        img = Image.open(img_path)  # Using PIL to open the image\n",
        "        img_tensor = data_transform(img)  # Transform the image to tensor\n",
        "        images.append(img_tensor)\n",
        "    display_images(class_name, images)\n",
        "\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Define the path to the dataset\n",
        "dataset_directory = \"/content/drive/MyDrive/Tomatoes\"\n",
        "\n",
        "# Function to display dimensions of images\n",
        "def display_image_dimensions(image_paths):\n",
        "    for img_path in image_paths:\n",
        "        img = Image.open(img_path)  # Using PIL to open the image\n",
        "        print(f\"Image shape: {np.array(img).shape}\")  # Convert to numpy array to get shape\n",
        "\n",
        "# Function to plot class distribution\n",
        "def plot_class_distribution():\n",
        "    class_counts = {}\n",
        "    for class_name in os.listdir(dataset_directory):\n",
        "        class_dir = os.path.join(dataset_directory, class_name)\n",
        "        if os.path.isdir(class_dir):  # Ensure it's a directory\n",
        "            class_counts[class_name] = len(os.listdir(class_dir))\n",
        "\n",
        "    plt.bar(class_counts.keys(), class_counts.values())\n",
        "    plt.xlabel('Class')\n",
        "    plt.ylabel('Number of Images')\n",
        "    plt.title('Class Distribution')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "# Perform EDA\n",
        "for class_name in os.listdir(dataset_directory):\n",
        "    class_dir = os.path.join(dataset_directory, class_name)\n",
        "    if os.path.isdir(class_dir):  # Ensure it's a directory\n",
        "        image_files = sorted(os.listdir(class_dir))[:5]  # Get the first 5 images\n",
        "        image_paths = [os.path.join(class_dir, image_file) for image_file in image_files]\n",
        "        print(f\"Class: {class_name}\")\n",
        "        display_image_dimensions(image_paths)\n",
        "\n",
        "plot_class_distribution()\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets, models\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the path to the dataset\n",
        "dataset_directory = \"/content/drive/MyDrive/Tomatoes\"\n",
        "\n",
        "# Define transformations for the dataset (resize and normalize)\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalization values for ImageNet\n",
        "])\n",
        "\n",
        "# Load the dataset\n",
        "image_dataset = datasets.ImageFolder(dataset_directory, transform=data_transform)\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "val_split = 0.2\n",
        "train_size = int((1 - val_split) * len(image_dataset))\n",
        "val_size = len(image_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(image_dataset, [train_size, val_size])\n",
        "\n",
        "# Define DataLoaders\n",
        "batch_size = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Define the model - ResNet18\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 3)  # Modify final fully connected layer for 3 classes\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Function to calculate accuracy\n",
        "def calculate_accuracy(outputs, labels):\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    total = labels.size(0)\n",
        "    accuracy = (correct / total) * 100\n",
        "    return accuracy\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 20\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Lists to store metrics for plotting\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        total_correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    epoch_accuracy = (total_correct / total_samples) * 100\n",
        "\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(epoch_accuracy)\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    val_total_correct = 0\n",
        "    val_total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_running_loss += loss.item() * inputs.size(0)\n",
        "            val_total_correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
        "            val_total_samples += labels.size(0)\n",
        "\n",
        "    val_epoch_loss = val_running_loss / len(val_dataset)\n",
        "    val_epoch_accuracy = (val_total_correct / val_total_samples) * 100\n",
        "\n",
        "    val_losses.append(val_epoch_loss)\n",
        "    val_accuracies.append(val_epoch_accuracy)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%, Val Loss: {val_epoch_loss:.4f}, Val Accuracy: {val_epoch_accuracy:.2f}%\")\n",
        "\n",
        "# Calculate overall accuracy on the validation set\n",
        "model.eval()\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        total_correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_preds.extend(outputs.argmax(dim=1).cpu().numpy())\n",
        "\n",
        "overall_accuracy = (total_correct / total_samples) * 100\n",
        "print(f\"\\nOverall Validation Accuracy: {overall_accuracy:.2f}%\")\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "# Display confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "classes = image_dataset.classes\n",
        "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(classes))\n",
        "plt.xticks(tick_marks, classes, rotation=45)\n",
        "plt.yticks(tick_marks, classes)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.tight_layout()\n",
        "\n",
        "# Print confusion matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "plt.show()\n",
        "\n",
        "# Plotting training metrics (loss and accuracy)\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Plotting training loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
        "plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss', color='g')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plotting training accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, num_epochs + 1), train_accuracies, label='Training Accuracy', color='r')\n",
        "plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy', color='g')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vizruoPJsCY",
        "outputId": "5835064e-ca97-4cd8-9487-bbffa1033d29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.13-py3-none-any.whl (328 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.5/328.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gtts\n",
            "  Downloading gTTS-2.5.1-py3-none-any.whl (29 kB)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.0.7)\n",
            "Installing collected packages: pydub, h11, httpcore, gtts, httpx, openai\n",
            "Successfully installed gtts-2.5.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.13 pydub-0.25.1\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}